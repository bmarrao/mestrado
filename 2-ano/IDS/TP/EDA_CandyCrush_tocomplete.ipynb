{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the Candy Crush dataset\n",
    "\n",
    "The dataset contains one week of data from a sample of players who played Candy Crush back in 2014. The data is also from a single episode, that is, a set of 15 levels. It has the following columns:\n",
    "\n",
    "* player_id: a unique player id\n",
    "* dt: the date\n",
    "* level: the level number within the episode, from 1 to 15.\n",
    "* num_attempts: number of level attempts for the player on that level and date.\n",
    "* num_success: number of level attempts that resulted in a success/win for the player on that level and date.\n",
    "\n",
    "The granularity of the dataset is player, date, and level. That is, there is a row for every player, day, and level recording the total number of attempts and how many of those resulted in a win."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T14:24:28.200433Z",
     "start_time": "2024-10-01T14:24:27.875496Z"
    }
   },
   "source": [
    "# load the dataset and count the number of rows and columns\n",
    "# df = ...\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load the 'ransom.csv' into a DataFrame\n",
    "df = pd.read_csv('../Datasets/candy_crush.csv')"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T14:27:21.875545Z",
     "start_time": "2024-10-01T14:27:21.823485Z"
    }
   },
   "source": [
    "# Count and display the number of unique players\n",
    "# Count unique values in a specific column, e.g., 'A'\n",
    "unique_count = df['player_id'].nunique()\n",
    "\n",
    "# Display the result\n",
    "print(unique_count)\n",
    "\n",
    "\n",
    "# Display the date range of the data. \n",
    "# To check the range of dates in a column of a Pandas DataFrame, you can use the min() and max() functions, just like you would for numerical data. However, you'll need to ensure that the column is of a date or datetime data type.\n",
    "print(df['dt'].min())\n",
    "print(df['dt'].max())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6814\n",
      "2014-01-01\n",
      "2014-01-07\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing level difficulty\n",
    "Within each Candy Crush episode, there is a mix of easier and tougher levels. Luck and individual skill make the number of attempts required to pass a level different from player to player. The assumption is that difficult levels require more attempts on average than easier ones. That is, the harder a level is, the lower the probability to pass that level in a single attempt is.\n",
    "\n",
    "A simple approach to model this probability is as a Bernoulli process; as a binary outcome (you either win or lose) characterized by a single parameter $Pwin$: the probability of winning the level in a single attempt. This probability can be estimated for each level as:\n",
    "\n",
    "$Pwin = \\frac{Sum (wins)}{Sum (attempts)}$\n",
    "\n",
    "For example, let's say a level has been played 10 times and 2 of those attempts ended up in a victory. Then the probability of winning in a single attempt would be pwin = 2 / 10 = 20%.\n",
    "\n",
    "Now, let's compute the difficulty Pwin separately for each of the 15 levels."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T14:49:37.282914Z",
     "start_time": "2024-10-01T14:49:21.685701Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your DataFrame has columns: 'level', 'attempts', 'success'\n",
    "min_level = min(df['level'])\n",
    "max_level = max(df['level'])\n",
    "\n",
    "levels = []\n",
    "pwin = []\n",
    "\n",
    "# Iterate over each level from min_level to max_level\n",
    "for level in range(min_level, max_level + 1):\n",
    "    # Filter the DataFrame for the current level\n",
    "    level_df = df.loc[df['level'] == level]\n",
    "\n",
    "    # Calculate total attempts and successes for the current level\n",
    "    total_attempts = len(level_df)\n",
    "    successes = len(level_df[level_df['success'] == 1])  # Assuming 1 represents success\n",
    "\n",
    "    # Calculate the ratio of success to attempts (pwin)\n",
    "    if total_attempts > 0:\n",
    "        ratio = successes / total_attempts\n",
    "    else:\n",
    "        ratio = 0  # To handle cases with zero attempts\n",
    "\n",
    "    # Store the level and pwin ratio\n",
    "    levels.append(level)\n",
    "    pwin.append(ratio)\n",
    "\n",
    "# Create a DataFrame with the results\n",
    "pwn_df = pd.DataFrame({'level': levels, 'pwin': pwin})\n",
    "\n",
    "# Display the result\n",
    "print(pwn_df)\n",
    "\n"
   ],
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'success'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3804\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3805\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3806\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32mindex.pyx:167\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mindex.pyx:196\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'success'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 17\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;66;03m# Calculate total attempts and successes for the current level\u001B[39;00m\n\u001B[1;32m     16\u001B[0m total_attempts \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(level_df)\n\u001B[0;32m---> 17\u001B[0m successes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(level_df[\u001B[43mlevel_df\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msuccess\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m])  \u001B[38;5;66;03m# Assuming 1 represents success\u001B[39;00m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m# Calculate the ratio of success to attempts (pwin)\u001B[39;00m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m total_attempts \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:4102\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   4100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   4101\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[0;32m-> 4102\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4103\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[1;32m   4104\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3807\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(casted_key, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[1;32m   3808\u001B[0m         \u001B[38;5;28misinstance\u001B[39m(casted_key, abc\u001B[38;5;241m.\u001B[39mIterable)\n\u001B[1;32m   3809\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m casted_key)\n\u001B[1;32m   3810\u001B[0m     ):\n\u001B[1;32m   3811\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n\u001B[0;32m-> 3812\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m   3813\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m   3814\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[1;32m   3815\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[1;32m   3816\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[1;32m   3817\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[0;31mKeyError\u001B[0m: 'success'"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the difficulty profile for all levels\n",
    "# choose the most appropriate type of visualization\n",
    "from matplotlib import pyplot as plt\n",
    "...\n",
    "\n",
    "# Add a horizontal dashed line at y=25\n",
    "plt.axhline(y=0.1, color='red', linestyle='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Uncertainty\n",
    "As Data Scientists we should always report some measure of the uncertainty of any provided numbers. Maybe tomorrow, another sample will give us slightly different values for the difficulties! Here we will simply use the Standard error as a measure of uncertainty:\n",
    "\n",
    "$S_{error} = \\frac{Ïƒ_{sample}}{\\sqrt{n}}$\n",
    "\n",
    "Here $n$ is the number of datapoints and $S$ sample is the sample standard deviation. For a Bernoulli process, the sample standard deviation is:\n",
    "\n",
    "$S_{sample} = \\sqrt{p_{win}(1-p_{win})}$\n",
    "\n",
    "Therefore, we can calculate the standard error like this:\n",
    "\n",
    "$S_{error} = \\sqrt{\\frac{p_{win}(1-p_{win})}{n}}$\n",
    "\n",
    "We already have all we need in the difficulty data frame! Every level has been played n number of times and we have their difficulty $p_{win}$. Now, let's calculate the standard error for each level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the standard error of p_win for each level\n",
    "\n",
    "# Create a barplot with standard errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating probabilities of winning\n",
    "One question a level designer might ask is: *How likely is it that a player will reach a level without losing a single time?* \n",
    "\n",
    "Let's calculate this using the estimated level difficulties!\n",
    "\n",
    "Recall that the probability of two independent events happening is simply the product of the individual probabilities. \n",
    "So the probability of winning both level 1 and level 2 on the first attempt would be:\n",
    "$p_win[1] * p_win[2]$\n",
    "\n",
    "To extend this to all level $Y$ you can use the multiplicatio all the numbers in a vector together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function that given the level calculates the probability of reaching that level without loosing.\n",
    "import numpy as np\n",
    "# until level 5\n",
    "np.prod(pwin[0:5])\n",
    "\n",
    "# develop a function that allows you to calculate the likelihood up to level $n$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
